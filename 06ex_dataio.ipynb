{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T16:24:36.468900Z",
     "start_time": "2023-12-01T16:24:36.404300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 10, 65, 49, 62, 49, 50, 14, 28, 46, 20, 54, 75, 19, 34, 82, 34, 52, 73, 5, 94, 88, 4, 62, 21, 26, 8, 0, 71, 32, 24, 4, 11, 92, 32, 22, 16, 79, 22, 71, 80, 34, 59, 22, 5, 74, 19, 24, 50, 97, 99, 79, 64, 29, 12, 56, 70, 90, 50, 8, 41, 40, 0, 82, 45, 20, 44, 67, 81, 77, 97, 61, 70, 84, 29, 10, 77, 18, 53, 90, 10, 1, 8, 34, 24, 50, 23, 41, 12, 14, 86, 44, 11, 4, 19, 36, 18, 86, 83, 38]\n",
      "67 10 65 49 62 49 50 14 28 46 20 54 75 19 34 82 34 52 73 5 94 88 4 62 21 26 8 0 71 32 24 4 11 92 32 22 16 79 22 71 80 34 59 22 5 74 19 24 50 97 99 79 64 29 12 56 70 90 50 8 41 40 0 82 45 20 44 67 81 77 97 61 70 84 29 10 77 18 53 90 10 1 8 34 24 50 23 41 12 14 86 44 11 4 19 36 18 86 83 38 [0.97244247 0.01554655 0.57493303 0.58277689 0.78054901] [0.11495134 0.5924458  0.42825044 0.12335759 0.20362403] [0.36006082 0.72709555 0.74968675 0.47166933 0.57662972] [0.04284741 0.51308072 0.12484319 0.89421807 0.01386045] [0.37837431 0.94165233 0.2699947  0.29943881 0.23631015] [0.97244247 0.01554655 0.57493303 0.58277689 0.78054901] [0.11495134 0.5924458  0.42825044 0.12335759 0.20362403] [0.36006082 0.72709555 0.74968675 0.47166933 0.57662972] [0.04284741 0.51308072 0.12484319 0.89421807 0.01386045] [0.37837431 0.94165233 0.2699947  0.29943881 0.23631015]\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from random import randrange\n",
    "from os import system\n",
    "\n",
    "# 1 crete and save data_int.txt\n",
    "list = []\n",
    "for i in range(100):\n",
    "    list.append(randrange(100))\n",
    "print(list)\n",
    "\n",
    "txt_file = open(\"data_int.txt\", \"w\")\n",
    "for element in list:\n",
    "    txt_file.write(str(element) + \" \")\n",
    "txt_file.close()\n",
    "\n",
    "system(\"cat data_int.txt\")\n",
    "\n",
    "# 5x5 floats\n",
    "matrix = np.random.rand(5, 5)\n",
    "txt_file2 = open(\"data_float.txt\", \"w\")\n",
    "for element in matrix:\n",
    "    txt_file2.write(str(element) + \" \")\n",
    "txt_file2.close()\n",
    "system(\"cat data_float.txt\")\n",
    "\n",
    "# txt convert to csv\n",
    "with open('data_float.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\",\") for line in stripped if line)\n",
    "    with open('data_float.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerows(lines)\n",
    "system(\"cat data_float.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file `user_data.json`, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T16:03:15.121332Z",
     "start_time": "2023-12-01T16:03:15.084598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID               JobTitle                       EmailAddress  \\\n",
      "1      2    Investment  Advisor       Clint_Thorpe5003@bulaffy.com   \n",
      "11    12         Retail Trainee   Phillip_Carpenter9505@famism.biz   \n",
      "27    28        Project Manager        Russel_Graves1378@extex.org   \n",
      "38    39            Stockbroker       Leanne_Newton1268@typill.biz   \n",
      "56    57         Budget Analyst          Tony_Giles1960@iatim.tech   \n",
      "61    62           CNC Operator        Owen_Allcott5125@bauros.biz   \n",
      "67    68        Project Manager           Liam_Lynn3280@kideod.biz   \n",
      "73    74                Dentist      Regina_Woodcock5820@yahoo.com   \n",
      "80    81          HR Specialist       Carter_Wallace9614@atink.com   \n",
      "91    92    Staffing Consultant           Maia_Stark2797@jiman.org   \n",
      "96    97            Stockbroker          Ciara_Lomax982@bauros.biz   \n",
      "115  116    Staffing Consultant      Isabel_Ellwood1475@fuliss.net   \n",
      "147  148           CNC Operator  Abdul_Townend2202@infotech44.tech   \n",
      "149  150             Fabricator        Caleb_Poulton1735@atink.com   \n",
      "150  151     Restaurant Manager         Ronald_Lewis6777@deavo.com   \n",
      "153  154                Bellman        Faith_Seymour3829@twace.org   \n",
      "168  169        Assistant Buyer      Anthony_Hancock9083@qater.org   \n",
      "175  176  Healthcare Specialist    Isabella_Willson5478@nanoff.biz   \n",
      "181  182             Pharmacist     Stephanie_Darcy3298@bauros.biz   \n",
      "198  199    Investment  Advisor         Ryan_Kennedy5565@corti.com   \n",
      "\n",
      "     FirstNameLastName           CreditCard    CreditCardType  \n",
      "1         Clint Thorpe  7083-8766-0251-2345  American Express  \n",
      "11   Phillip Carpenter  3657-0088-0820-5247  American Express  \n",
      "27       Russel Graves  6718-4818-8011-6024  American Express  \n",
      "38       Leanne Newton  5438-0816-4166-4847  American Express  \n",
      "56          Tony Giles  8130-3425-7573-7745  American Express  \n",
      "61        Owen Allcott  4156-0107-7210-2630  American Express  \n",
      "67           Liam Lynn  7152-3247-6053-2233  American Express  \n",
      "73     Regina Woodcock  0208-1753-3870-8002  American Express  \n",
      "80      Carter Wallace  4256-7201-6717-4322  American Express  \n",
      "91          Maia Stark  3851-1403-1734-6321  American Express  \n",
      "96         Ciara Lomax  3702-3440-2472-5424  American Express  \n",
      "115     Isabel Ellwood  3738-0882-0066-6683  American Express  \n",
      "147      Abdul Townend  4224-1226-3557-3448  American Express  \n",
      "149      Caleb Poulton  8203-6875-5225-0341  American Express  \n",
      "150       Ronald Lewis  7212-0155-5014-8471  American Express  \n",
      "153      Faith Seymour  4170-5186-6887-6558  American Express  \n",
      "168    Anthony Hancock  0832-3357-6010-6550  American Express  \n",
      "175   Isabella Willson  5177-4868-4623-0384  American Express  \n",
      "181    Stephanie Darcy  0264-4020-5106-5576  American Express  \n",
      "198       Ryan Kennedy  3166-6287-6242-7207  American Express  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_json(\"user_data.json\")\n",
    "file = file[(file['CreditCardType'] == \"American Express\")]\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T16:01:01.572316Z",
     "start_time": "2023-12-01T16:01:01.479638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cap-shape  cap-surface  cap-color   bruises      odor  gill-attachment  \\\n",
      "class                                                                           \n",
      "0       3.266160     1.615970   4.581749  0.653992  4.334601         0.954373   \n",
      "1       3.436159     2.055158   4.421859  0.159346  3.940756         0.995403   \n",
      "\n",
      "       gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
      "class                                                    ...   \n",
      "0          0.285171   0.068441    6.622624     0.615970  ...   \n",
      "1          0.028601   0.567926    2.863636     0.514811  ...   \n",
      "\n",
      "       stalk-surface-below-ring  stalk-color-above-ring  \\\n",
      "class                                                     \n",
      "0                      1.798479                6.098859   \n",
      "1                      1.394280                5.512768   \n",
      "\n",
      "       stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
      "class                                                                          \n",
      "0                    6.064639        0.0    1.931559     1.125475   3.007605   \n",
      "1                    5.504597        0.0    2.002043     1.009193   1.522983   \n",
      "\n",
      "       spore-print-color  population   habitat  \n",
      "class                                           \n",
      "0               3.201521    3.283270  1.148289  \n",
      "1               4.021450    4.031665  1.895812  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "{\"cap-shape\":{\"0\":3.2661596958,\"1\":3.4361593463},\"cap-surface\":{\"0\":1.6159695817,\"1\":2.0551583248},\"cap-color\":{\"0\":4.5817490494,\"1\":4.4218590398},\"bruises\":{\"0\":0.6539923954,\"1\":0.1593462717},\"odor\":{\"0\":4.3346007605,\"1\":3.9407558733},\"gill-attachment\":{\"0\":0.9543726236,\"1\":0.9954034729},\"gill-spacing\":{\"0\":0.2851711027,\"1\":0.0286006129},\"gill-size\":{\"0\":0.0684410646,\"1\":0.5679264556},\"gill-color\":{\"0\":6.6226235741,\"1\":2.8636363636},\"stalk-shape\":{\"0\":0.6159695817,\"1\":0.5148110317},\"stalk-root\":{\"0\":1.4980988593,\"1\":0.6925434116},\"stalk-surface-above-ring\":{\"0\":1.7756653992,\"1\":1.3595505618},\"stalk-surface-below-ring\":{\"0\":1.7984790875,\"1\":1.3942798774},\"stalk-color-above-ring\":{\"0\":6.0988593156,\"1\":5.5127681307},\"stalk-color-below-ring\":{\"0\":6.0646387833,\"1\":5.5045965271},\"veil-type\":{\"0\":0.0,\"1\":0.0},\"veil-color\":{\"0\":1.9315589354,\"1\":2.0020429009},\"ring-number\":{\"0\":1.1254752852,\"1\":1.0091930541},\"ring-type\":{\"0\":3.0076045627,\"1\":1.5229826353},\"spore-print-color\":{\"0\":3.2015209125,\"1\":4.0214504597},\"population\":{\"0\":3.283269962,\"1\":4.0316649642},\"habitat\":{\"0\":1.1482889734,\"1\":1.8958120531}}"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"mushrooms_categorized.csv\")\n",
    "data =data.groupby('class').mean()\n",
    "print(data)\n",
    "data.to_json('mushrooms_categorized.json')\n",
    "\n",
    "system(\"cat mushrooms_categorized.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading a database**\n",
    "\n",
    "Get the database `sakila.db` from the lecture `06_dataio.ipynb`, and import the table `actors` as a Pandas dataframe. Using the dataframe, count how many actors have a first name that begins with `A`.\n",
    "\n",
    "*Hint:* use the Series `.str` method to apply the Python string methods to the elements of a Series, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-07 17:24:02--  https://gist.github.com/Piyush3dB/726bf7012785d6e0fd691c3655c92654/raw/2c17ccb2eb33b3396bfa96284c53f0718a4ea62c/sakila.db\r\n",
      "Resolving gist.github.com (gist.github.com)... 140.82.121.4\r\n",
      "Connecting to gist.github.com (gist.github.com)|140.82.121.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\r\n",
      "Location: https://gist.githubusercontent.com/Piyush3dB/726bf7012785d6e0fd691c3655c92654/raw/2c17ccb2eb33b3396bfa96284c53f0718a4ea62c/sakila.db [following]\r\n",
      "--2023-12-07 17:24:02--  https://gist.githubusercontent.com/Piyush3dB/726bf7012785d6e0fd691c3655c92654/raw/2c17ccb2eb33b3396bfa96284c53f0718a4ea62c/sakila.db\r\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\r\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 5828608 (5.6M) [application/octet-stream]\r\n",
      "Saving to: ‘./data/sakila.db.2’\r\n",
      "\r\n",
      "sakila.db.2         100%[===================>]   5.56M  33.1MB/s    in 0.2s    \r\n",
      "\r\n",
      "2023-12-07 17:24:02 (33.1 MB/s) - ‘./data/sakila.db.2’ saved [5828608/5828608]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://gist.github.com/Piyush3dB/726bf7012785d6e0fd691c3655c92654/raw/2c17ccb2eb33b3396bfa96284c53f0718a4ea62c/sakila.db -P ./data/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-07T16:24:02.919662Z",
     "start_time": "2023-12-07T16:24:02.013062Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-07T16:27:29.380391Z",
     "start_time": "2023-12-07T16:27:29.334735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": "       0         1             2                    3\n0      1  PENELOPE       GUINESS  2019-02-16 18:17:33\n1      2      NICK      WAHLBERG  2019-02-16 18:17:33\n2      3        ED         CHASE  2019-02-16 18:17:33\n3      4  JENNIFER         DAVIS  2019-02-16 18:17:33\n4      5    JOHNNY  LOLLOBRIGIDA  2019-02-16 18:17:33\n..   ...       ...           ...                  ...\n195  196      BELA        WALKEN  2019-02-16 18:17:33\n196  197     REESE          WEST  2019-02-16 18:17:33\n197  198      MARY        KEITEL  2019-02-16 18:17:33\n198  199     JULIA       FAWCETT  2019-02-16 18:17:33\n199  200     THORA        TEMPLE  2019-02-16 18:17:33\n\n[200 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>PENELOPE</td>\n      <td>GUINESS</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NICK</td>\n      <td>WAHLBERG</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>ED</td>\n      <td>CHASE</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>JENNIFER</td>\n      <td>DAVIS</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>JOHNNY</td>\n      <td>LOLLOBRIGIDA</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>196</td>\n      <td>BELA</td>\n      <td>WALKEN</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>197</td>\n      <td>REESE</td>\n      <td>WEST</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>198</td>\n      <td>MARY</td>\n      <td>KEITEL</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>199</td>\n      <td>JULIA</td>\n      <td>FAWCETT</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>200</td>\n      <td>THORA</td>\n      <td>TEMPLE</td>\n      <td>2019-02-16 18:17:33</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dependency\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "\n",
    "# create a connection to the database and a cursor to execute queries\n",
    "conn = sql.connect('sakila.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# query data from database: select all content from the table \"actor\"\n",
    "query = \"SELECT * FROM actor\"\n",
    "results = cur.execute(query).fetchall()\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df[df[1].str.startswith('A')].shape[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named `credit_card.dat` from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T16:05:05.504635Z",
     "start_time": "2023-12-01T16:05:05.492774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7648 5673 3775 2271', '3257 8247 3354 2266', '2722 0001 4011 6652', '0661 3063 3742 3150', '0432 1608 1462 4742', '5827 2027 8785 7303', '5774 8528 2087 1117', '8140 1210 6352 2845', '5764 1133 7301 7100', '6456 1737 4126 6726', '1228 8631 7382 0000', '7051 0160 5374 3166', '0618 3587 1630 6376', '1545 5454 7444 5636', '6735 3116 3202 6834', '7287 5011 1547 8413', '7033 2607 3328 4200', '2568 5244 1874 5024', '1684 2253 7570 7118', '0672 2576 0575 6631', '6332 8353 8787 1340', '1813 3361 1175 4211', '2477 6450 8840 2368', '5512 3505 2563 1326', '3083 7882 0621 0025', '4521 5148 8045 0334', '7563 3654 8713 5787', '8324 2664 0476 5561', '0565 2504 7168 3510', '5107 5507 1767 0738', '2462 1821 2448 1443', '2788 0638 6861 6554', '5851 5873 5474 0547', '0670 1004 4013 2655', '5874 5506 3048 0806', '2805 5401 8462 1260', '5083 8406 6310 1862', '1076 1445 3013 2266', '8440 4804 4844 5277', '4758 6141 0686 1387', '7586 0675 0315 2568', '2544 1258 7432 5165', '3474 5023 4434 5626', '1410 0270 0434 5086', '7315 4446 1104 4215', '0224 7742 8300 0266', '0170 2700 3145 0640', '2006 2437 8054 1600', '8142 4055 1776 0026', '3026 7380 1241 1084', '']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_name = 'credit_card.dat'\n",
    "credit_cards = []\n",
    "with open(file_name, mode='r') as f:\n",
    "    for line in f:\n",
    "        n = 6\n",
    "        bin_chars = [line[i:i + n] for i in range(0, len(line) - 5, n)]\n",
    "\n",
    "        card_number = \"\"\n",
    "        for char in bin_chars:\n",
    "            card_number += chr(int(char, 2))\n",
    "\n",
    "        credit_cards.append(card_number)\n",
    "\n",
    "print(credit_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, \"pack\" the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_dataio.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T16:20:46.244459Z",
     "start_time": "2023-12-01T16:20:46.219605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "64-Bit Word for row 0: 4681436006502574298\n",
      "\n",
      "64-Bit Word for row 1: 4681998956455995611\n",
      "\n",
      "64-Bit Word for row 2: 4647659009297301308\n",
      "\n",
      "64-Bit Word for row 3: 4648221959250722771\n",
      "\n",
      "64-Bit Word for row 4: 4648221959250729241\n",
      "\n",
      "64-Bit Word for row 5: 4647659009297307972\n",
      "\n",
      "64-Bit Word for row 6: 4646533109390465678\n",
      "\n",
      "64-Bit Word for row 7: 4690443205757328128\n",
      "\n",
      "64-Bit Word for row 8: 4647096059343887061\n",
      "\n",
      "64-Bit Word for row 9: 4645970159437044871\n",
      "\n",
      "\n",
      "Original Data from Text File Before Conversion:\n"
     ]
    },
    {
     "data": {
      "text/plain": "   HEAD  FPGA  TDC_CHANNEL   ORBIT_CNT  BX_COUNTER  TDC_MEAS\n0     1     0          123  3869200167        2374        26\n1     1     0          124  3869200167        2374        27\n2     1     0           63  3869200167        2553        28\n3     1     0           64  3869200167        2558        19\n4     1     0           64  3869200167        2760        25\n5     1     0           63  3869200167        2762         4\n6     1     0           61  3869200167        2772        14\n7     1     0          139  3869200167        2776         0\n8     1     0           62  3869200167        2774        21\n9     1     0           60  3869200167        2788         7",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HEAD</th>\n      <th>FPGA</th>\n      <th>TDC_CHANNEL</th>\n      <th>ORBIT_CNT</th>\n      <th>BX_COUNTER</th>\n      <th>TDC_MEAS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>123</td>\n      <td>3869200167</td>\n      <td>2374</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>124</td>\n      <td>3869200167</td>\n      <td>2374</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>63</td>\n      <td>3869200167</td>\n      <td>2553</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>64</td>\n      <td>3869200167</td>\n      <td>2558</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>64</td>\n      <td>3869200167</td>\n      <td>2760</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>0</td>\n      <td>63</td>\n      <td>3869200167</td>\n      <td>2762</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>0</td>\n      <td>61</td>\n      <td>3869200167</td>\n      <td>2772</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>0</td>\n      <td>139</td>\n      <td>3869200167</td>\n      <td>2776</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>62</td>\n      <td>3869200167</td>\n      <td>2774</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>0</td>\n      <td>60</td>\n      <td>3869200167</td>\n      <td>2788</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "from IPython.display import Image\n",
    "Image(\"data_format.png\")\n",
    "\n",
    "file_name= \"data/data_000637.txt\"\n",
    "data = pd.read_csv(file_name, nrows=10, skiprows=range(1,1))\n",
    "columns = ['HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS']\n",
    "\n",
    "with open('bin_file.dat','wb') as binary_file:\n",
    "    for i in range(len(data)):\n",
    "        head = data['HEAD'].loc[i]\n",
    "        fpga = data['FPGA'].loc[i]\n",
    "        tdc_channel = data['TDC_CHANNEL'].loc[i]\n",
    "        orbit_cnt = data['ORBIT_CNT'].loc[i]\n",
    "        bx_cnt = data['BX_COUNTER'].loc[i]\n",
    "        tdc_meas = data['TDC_MEAS'].loc[i]\n",
    "        \n",
    "        \n",
    "        \n",
    "        b_head = int(bin((head & 0x3))[2:].zfill(2),2) << 62\n",
    "        b_fpga = int(bin(fpga & 0xF)[2:].zfill(4),2) << 58\n",
    "        b_tdc_channel = int(bin(tdc_channel & 0x1FF)[2:].zfill(9),2) << 49\n",
    "        b_orbit_cnt = int(bin(orbit_cnt & 0xFFFFFFFF)[2:].zfill(32),2) << 17\n",
    "        bbx_cnt = int(bin(bx_cnt & 0xFFF)[2:].zfill(12),2) << 5\n",
    "        b_tdc_meas = int(bin(tdc_meas & 0x1F)[2:].zfill(5),2) << 0\n",
    "\n",
    "\n",
    "\n",
    "        words = b_head|b_fpga|b_tdc_channel|b_orbit_cnt|bbx_cnt|b_tdc_meas\n",
    "        print('\\n64-Bit Word for row %d:' %i,words)\n",
    "        binary_file.write( struct.pack('<q', words) )\n",
    "binary_file.close()\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\nOriginal Data from Text File Before Conversion:')\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
